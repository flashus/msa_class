# Тут перечисляются глобальные переменные для пайплайна.
# Их мы будем использовать дальше в файле.
# Блок переменных имеет зарезервированное имя variables, которое не должно использоваться в качестве имени шага:
variables:
  JAVA_VERSION: 17
  APP_IMAGE: test-app
  # В переменных можно ссылаться на другие переменные, в том числе те, которые предоставляет GitLab.
  # Таких переменных довольно много, и можно, например, получить информацию о теге коммита:
  APP_TAG: $CI_COMMIT_TAG
  # SONAR_USER_HOME: "$CI_PROJECT_DIR/.sonar"
  # GIT_DEPTH: "0"

  # Укажем имя для релиза helm chart'a
  APP_RELEASE: users
  # Имена для веток разработки и релиза
  BRANCH_DEV: dev
  BRANCH_RELEASE: main
  # Название промышленного окружения
  ENV_PRODUCTION: prod
  # И образ для пайплайна с kubectl и helm
  IMG_K8S: alpine/k8s:1.20.15

# Здесь перечислены этапы сборки в нужном порядке.
# Называть этапы можно как угодно:
stages:
- build
- test
- build_image
# - code_quality
# - deploy_dev
- deploy
- smoke
# - deploy_test
- release
- regression
- load
- production

# Опишем шаблон деплоя, чтобы не писать его снова и снова. В Gitlab имена шаблонов начинают с точки
.deploy:
  # Указываем этап, образ и команду деплоя при помощи helm
  stage: deploy
  image: $IMG_K8S
  script:
  - echo "Starting"
  - kubectl config get-contexts
  - kubectl config use-context flash.us/msa_class:users-k8s-agent
  - kubectl get pods
  - cd .chart && helm upgrade $APP_RELEASE-$ENV . -i -f values-$ENV.yaml
  # - helm upgrade -f values-$ENV --atomic --install $APP_RELEASE-$ENV

  # В блоке environment указываем имя окружения, это позволит gitlab поддерживать история деплоев на разные среды, что может быть интересно в будущем для анализа активности по проекту
  environment:
    name: $ENV

# Чтобы использовать результаты сборки на разных шагах, добавим кеш, иначе собрать артефакт с JAR-файлом, полученным на этапе build_app, нельзя:
cache:
  key: "$CI_COMMIT_REF_SLUG-build-cache"
  paths:
  - build/

# Далее описываем шаги сборки. Называть их можно практически как угодно, нельзя лишь использовать зарезервированные имена:
build-app:
  # Привязываем шаг к определённому этапу:
  stage: build
  # Указываем образ, который будет использоваться для выполнения шага:
  # image: openjdk:$JAVA_VERSION
  image: gradle:8.6-jdk$JAVA_VERSION
  # В разделе скрипта задаём команду, которую хотим выполнить:
  script: "./gradlew assemble"
  # script: "chmod +x ./gradlew && ./gradlew assemble"

run-tests:
  stage: test
  # Обратите внимание на переиспользование переменных:
  # image: openjdk:$JAVA_VERSION
  image: gradle:8.6-jdk$JAVA_VERSION
  script: ./gradlew test
  needs:
  - build-app

run-smoke:
  stage: smoke
  image: gradle:8.6-jdk$JAVA_VERSION
  # services:
  # - postgres:latest
  # variables:
  #   POSTGRES_DB: your_db
  #   POSTGRES_USER: user
  #   POSTGRES_PASSWORD: password
  script: ./gradlew integrationTest --tests ru.idyachenko.users.smoke.SmokeTest
  needs:
  - build-app
  - run-tests

run-regression:
  stage: regression
  image: gradle:8.6-jdk$JAVA_VERSION
  script: ./gradlew integrationTest --tests ru.idyachenko.users.regression.RegressionTest
  needs:
  - build-app
  - run-tests
  - run-smoke

# run_sonar:
#   stage: code_quality
#   image: gradle:8.6-jdk$JAVA_VERSION
#   cache:
#     key: "$CI_JOB_NAME-$CI_COMMIT_REF_SLUG-sonar-cache"
#     paths:
#     - ".sonar/cache"
#   script: ./gradlew sonarqube
#   rules:
#   - if: "$CI_BUILD_REF_NAME != 'main' && $CI_PIPELINE_SOURCE == 'push' || $CI_PIPELINE_SOURCE == 'merge_request_event' "

build-artifact:
  stage: build_image
  # Для сборки образа будем использовать механизм docker in docker:
  image: docker:latest
  # Во внутреннем блоке variables можно задавать локальные переменные шага:
  variables:
    DOCKER_TLS_CERTDIR: /certs
  # Раздел services позволяет добавить к сборке ещё несколько образов.
  # Например, для docker in docker нам нужен образ с демоном. 
  # Другой пример: можно добавить БД для интеграционных тестов в отдельном образе.
  # Все эти образы будут работать вместе на текущем шаге:
  services:
  - docker:dind
  # В разделе before_script можно указать шаги, которые необходимо выполнить перед основным скриптом.
  # Обратите внимание на переменные, которых нет в файле пайплайна, они задаются в настройках проекта.
  # Это позволяет хранить чувствительные данные отдельно от кода, причём благодаря ролевой модели GitLab.
  # Доступ к ним можно оставить только администратору или владельцу проекта, что повышает безопасность:
  before_script:
  # - docker login -u $REGISTRY_USER -p $REGISTRY_PASS
  - docker login -u $REGISTRY_USER -p $DOCKER_TOKEN
  - apk update && apk add git
  # Если скрипт состоит более чем из одной команды, то удобно использовать list-форму.
  # В этой форме каждая команда записывается в отдельный элемент списка, что повышает читаемость файла:
  script:
  - docker build -t $REGISTRY_USER/$APP_IMAGE:$APP_TAG .
  - docker push $REGISTRY_USER/$APP_IMAGE:$APP_TAG
  needs:
  - build-app
  - run-tests
  - run-smoke
  - run-regression

# deploy_artifact_dev:
#   stage: deploy_dev
#   image:
#     name: flashus/k8s_deploy:1.0.0
#     entrypoint: ['']
#   script:
#   - kubectl config get-contexts
#   - kubectl config use-context flash.us/msa_class:users-k8s-agent
#   - kubectl get pods
#   - cd .chart && helm upgrade users-dev . -i -f values-dev.yaml

# deploy_artifact_test:
#   stage: deploy_test
#   image:
#     name: flashus/k8s_deploy:1.0.0
#     entrypoint: ['']
#   script:
#   - kubectl config get-contexts
#   - kubectl config use-context flash.us/msa_class:users-k8s-agent
#   - kubectl get pods
#   - cd .chart && helm upgrade users-test . -i -f values-test.yaml


# Опишем шаг деплоя в dev окружение
deploy-to-dev:
  # указываем родительский шаблон
  extends: .deploy
  # И конкретные значения переменных, которые в него передаются
  variables:
    ENV: dev
  # В блоке only укажем что шаг должен запускаться только при коммитах в ветку dev
  # Если ветка отличается, то шаг будет пропущен
  only:
  - dev
  needs:
  - build-artifact

stress-test:
  stage: load
  image:
    name: direvius/yandex-tank:latest
    entrypoint: ['']
  # script:
  # - cd .load && tank run
  script: chmod +x ./load/yandextank.sh && ./load/yandextank.sh
  artifacts:
    paths:
    - yandextank_report
  needs:
  - deploy-to-dev

# Теперь опишем деплой в тестовое окружение
deploy-to-test:
  extends: .deploy
  variables:
    ENV: test
  # Другой способ для описания условий для запуска пайплайна - блок rules
  rules:
  # Тут можно задать условие: название ветки с коммитом должно совпадать со значением переменной $BRANCH_DEV
  # when: manual означает что требуется подтверждение для запуска этого шага (мы ведь не хотим случайно сломать тестерам их окружение)
  # пайлайн будет находиться в состоянии blocked до тех пор пока шаг не будет подтвержден
  - if: $CI_COMMIT_BRANCH == $BRANCH_DEV
  when: manual
  needs:
  - build-artifact

# Деплой в препрод будем осуществлять только после мержа dev -> main, так мы обеспечим больший контроль над релизами
deploy-to-preprod:
  extends: .deploy
  variables:
    ENV: preprod
  rules:
  - if: $CI_COMMIT_REF_NAME == $BRANCH_RELEASE
  needs:
  - build-artifact

# В случае если у коммита есть тэг, мы так же создадим и релиз в Gitlab, он нам тоже пригодится для истории
release:
  stage: release
  image: registry.gitlab.com/gitlab-org/release-cli:latest
  release:
    tag_name: $CI_COMMIT_TAG
    description: "$CI_COMMIT_MESSAGE"
  # Ключевое слово tags указывает что данный шаг будет применим только к коммитам тегов
  only:
  - tags
  script:
  - echo "Creating release"
  needs:
  - build-artifact

# Шаг деплоя в продакшен выделим в отдельный этап, т.к. это важная веха в жизненном цикле приложения
deploy-to-production:
  stage: production
  extends: .deploy
  variables:
    ENV: $ENV_PRODUCTION
  # Деплоить в продакшен мы можем только из релизной ветки и только после ручного подтверждения, когда все участники процесса к этому готовы. Пока не получим подтверждение выполнение пайплайна будет заблокировано.
  rules:
  - if: $CI_COMMIT_REF_NAME == $BRANCH_RELEASE
  when: manual
  needs:
  - build-artifact

# Добавим к шагу деплой и шаг отката. Вообще в Gitlab CI откаты обычно реализуют иначе, достаточно просто заново запустить любой предыдущий пайплайн, при этом гитлаб переключится на соответствующий коммит и выполнит шаги раскатки предыдущей стабильной версии. Такой подход не зависит от инструментов автоматизации, и может применяться в любом проекте.
# Тут для примера откат выполняет отдельным опциональным шагом при помощи helm rollback, причем сам шаг доступен только после того как выполнится деплой и требует ручного запуска.
rollback:
  stage: production
  image: $IMG_K8S
  interruptible: true
  # Откат доступен только после выполнения шага deploy-to-production
  needs:
  - deploy-to-production
  # В блоке only можно использовать форму variables, которая позволяет сравнивать друг с другом переменные и еще гибче настраивать условия пропуска шага. В отличии от блока rules, использование only не блокирует пайплайн, но шаг все же можно запустить вручную, именно такое поведение нам нужно для этого шага.
  only:
    variables:
    - $CI_COMMIT_REF_NAME == $BRANCH_RELEASE
  # Обязательно запускаем только руками
  when: manual
  # Факт отката так же фиксируем в истории деплоев
  environment:
    name: $ENV_PRODUCTION
  # Сам откат будем делать при помощи helm rollback
  script:
  - helm rollback $APP_RELEASE-$ENV_PRODUCTION
